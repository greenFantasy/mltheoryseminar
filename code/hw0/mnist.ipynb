{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torchvision.datasets as ds\n",
    "import pylab as plt\n",
    "from scipy.linalg import svdvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(datadir='./data_cache'):\n",
    "    train_ds = ds.MNIST(root=datadir, train=True,\n",
    "                           download=True, transform=None)\n",
    "    test_ds = ds.MNIST(root=datadir, train=False,\n",
    "                          download=True, transform=None)\n",
    "\n",
    "    def to_xy(dataset):\n",
    "        X = np.array(dataset.data) / 255.0  # [0, 1]\n",
    "        Y = np.array(dataset.targets)\n",
    "        return X, Y\n",
    "\n",
    "    X_tr, Y_tr = to_xy(train_ds)\n",
    "    X_te, Y_te = to_xy(test_ds)\n",
    "    return X_tr, Y_tr, X_te, Y_te\n",
    "\n",
    "X_tr, Y_tr, X_te, Y_te = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.choice(len(X_tr))\n",
    "plt.imshow(X_tr[i], cmap='gray');\n",
    "plt.title(f'digit: {Y_tr[i]}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original X_tr: (60000, 28, 28)\n",
      "reshaped X: (500, 784)\n",
      "reshaped Y: (500,)\n"
     ]
    }
   ],
   "source": [
    "print('original X_tr:', X_tr.shape)\n",
    "\n",
    "# select 500 random examples\n",
    "n = 500\n",
    "I = np.random.choice(len(X_tr), n, replace=False)\n",
    "X = X_tr[I]\n",
    "Y = (Y_tr[I] % 2) * 2.0 - 1 # odd/even --> +1/-1\n",
    "X = X.reshape(-1,  28*28) # flatten\n",
    "\n",
    "print('reshaped X:', X.shape)\n",
    "print('reshaped Y:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_rank(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = np.matmul(np.linalg.pinv(X), Y)\n",
    "np.allclose(np.matmul(X, beta), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now finding how much error our linear regression weight beta has on the test set\n",
    "# First, set up test set:\n",
    "\n",
    "X_te_mod = X_te.reshape(-1, 28*28)\n",
    "Y_te_mod = (Y_te % 2) * 2.0 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.67009086229678"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, we compute MSE on this test set:\n",
    "def mse(beta, X, Y):\n",
    "    return np.mean(np.square(np.matmul(X, beta) - Y))\n",
    "\n",
    "mse(beta, X_te_mod, Y_te_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Trials Average MSE: 15.219902966695926\n"
     ]
    }
   ],
   "source": [
    "mses = []\n",
    "for _ in range(20):\n",
    "    n = 500\n",
    "    I = np.random.choice(len(X_tr), n, replace=False)\n",
    "    X_temp = X_tr[I]\n",
    "    Y_temp = (Y_tr[I] % 2) * 2.0 - 1 # odd/even --> +1/-1\n",
    "    X_temp = X_temp.reshape(-1,  28*28) # flatten\n",
    "    \n",
    "    beta = np.matmul(np.linalg.pinv(X_temp), Y_temp)\n",
    "    mses.append(mse(beta, X_te_mod, Y_te_mod))\n",
    "\n",
    "print(f'20 Trials Average MSE: {np.mean(mses)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(beta, X, Y):\n",
    "    return np.mean(1 - (np.abs(np.where(np.matmul(X, beta) > 0, 1, -1) - Y) / 2))\n",
    "\n",
    "accuracy(beta, X_te_mod, Y_te_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(beta, X, Y):\n",
    "    return 2 * np.matmul(X.T, np.matmul(X, beta) - Y)\n",
    "\n",
    "def stochastic_gradient(beta, X, Y, batch_size=1):\n",
    "    I = np.random.choice(len(X), batch_size, replace=False)\n",
    "    temp_X = X[I]\n",
    "    temp_Y = Y[I]\n",
    "    return gradient(beta, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(X, Y, lr=0.00003, epochs=1000, epochs_per_print=20, low=-.1, high=.1, X_te=None, Y_te=None):\n",
    "    gen = np.random.default_rng()\n",
    "    beta = gen.uniform(low=low, high=high, size=784)\n",
    "    for i in range(epochs):\n",
    "        beta -= lr * gradient(beta, X, Y)\n",
    "        if i % epochs_per_print == 0 or (i % 100 == 0 and i <= 2000): \n",
    "            tr_loss = mse(beta, X, Y)\n",
    "            tr_acc = accuracy(beta, X, Y)\n",
    "            print(f'Epoch {i}', f\"Train Accuracy: {tr_acc:.3f}\", f'Training Loss: {tr_loss:.3f}', sep='\\t', end='')\n",
    "            if X_te is not None and Y_te is not None:\n",
    "                te_acc = accuracy(beta, X_te, Y_te)\n",
    "                print(f\"\\tTest Accuracy: {te_acc:.3f}\")\n",
    "            else:\n",
    "                print()\n",
    "    return beta\n",
    "\n",
    "def sgd(X, Y, lr=0.00003, epochs=1000, epochs_per_print=20, low=-.1, high=.1, X_te=None, Y_te=None, batch_size=1):\n",
    "    gen = np.random.default_rng()\n",
    "    beta = gen.uniform(low=low, high=high, size=784)\n",
    "    for i in range(epochs):\n",
    "        beta -= lr * stochastic_gradient(beta, X, Y, batch_size=batch_size)\n",
    "        if i % epochs_per_print == 0 or (i % 100 == 0 and i <= 2000): \n",
    "            tr_loss = mse(beta, X, Y)\n",
    "            tr_acc = accuracy(beta, X, Y)\n",
    "            print(f'Epoch {i}', f\"Train Accuracy: {tr_acc:.3f}\", f'Training Loss: {tr_loss:.3f}', sep='\\t', end='')\n",
    "            if X_te is not None and Y_te is not None:\n",
    "                te_acc = accuracy(beta, X_te, Y_te)\n",
    "                print(f\"\\tTest Accuracy: {te_acc:.3f}\")\n",
    "            else:\n",
    "                print()\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\tTrain Accuracy: 0.608\tTraining Loss: 0.912\tTest Accuracy: 0.611\n",
      "Epoch 100\tTrain Accuracy: 0.894\tTraining Loss: 0.381\tTest Accuracy: 0.840\n",
      "Epoch 200\tTrain Accuracy: 0.918\tTraining Loss: 0.337\tTest Accuracy: 0.845\n",
      "Epoch 300\tTrain Accuracy: 0.932\tTraining Loss: 0.309\tTest Accuracy: 0.844\n",
      "Epoch 400\tTrain Accuracy: 0.940\tTraining Loss: 0.290\tTest Accuracy: 0.845\n",
      "Epoch 500\tTrain Accuracy: 0.946\tTraining Loss: 0.274\tTest Accuracy: 0.844\n",
      "Epoch 600\tTrain Accuracy: 0.944\tTraining Loss: 0.262\tTest Accuracy: 0.844\n",
      "Epoch 700\tTrain Accuracy: 0.948\tTraining Loss: 0.251\tTest Accuracy: 0.842\n",
      "Epoch 800\tTrain Accuracy: 0.950\tTraining Loss: 0.242\tTest Accuracy: 0.841\n",
      "Epoch 900\tTrain Accuracy: 0.956\tTraining Loss: 0.234\tTest Accuracy: 0.839\n",
      "Epoch 1000\tTrain Accuracy: 0.960\tTraining Loss: 0.227\tTest Accuracy: 0.838\n",
      "Epoch 1100\tTrain Accuracy: 0.962\tTraining Loss: 0.221\tTest Accuracy: 0.839\n",
      "Epoch 1200\tTrain Accuracy: 0.962\tTraining Loss: 0.215\tTest Accuracy: 0.839\n",
      "Epoch 1300\tTrain Accuracy: 0.964\tTraining Loss: 0.210\tTest Accuracy: 0.837\n",
      "Epoch 1400\tTrain Accuracy: 0.966\tTraining Loss: 0.205\tTest Accuracy: 0.836\n",
      "Epoch 1500\tTrain Accuracy: 0.972\tTraining Loss: 0.200\tTest Accuracy: 0.836\n",
      "Epoch 1600\tTrain Accuracy: 0.974\tTraining Loss: 0.196\tTest Accuracy: 0.835\n",
      "Epoch 1700\tTrain Accuracy: 0.974\tTraining Loss: 0.192\tTest Accuracy: 0.835\n",
      "Epoch 1800\tTrain Accuracy: 0.976\tTraining Loss: 0.188\tTest Accuracy: 0.833\n",
      "Epoch 1900\tTrain Accuracy: 0.976\tTraining Loss: 0.185\tTest Accuracy: 0.833\n",
      "Epoch 2000\tTrain Accuracy: 0.980\tTraining Loss: 0.181\tTest Accuracy: 0.832\n",
      "Epoch 5000\tTrain Accuracy: 0.986\tTraining Loss: 0.126\tTest Accuracy: 0.816\n",
      "Epoch 10000\tTrain Accuracy: 0.994\tTraining Loss: 0.094\tTest Accuracy: 0.800\n",
      "Epoch 15000\tTrain Accuracy: 0.998\tTraining Loss: 0.079\tTest Accuracy: 0.789\n",
      "Epoch 20000\tTrain Accuracy: 0.998\tTraining Loss: 0.071\tTest Accuracy: 0.781\n",
      "Epoch 25000\tTrain Accuracy: 1.000\tTraining Loss: 0.065\tTest Accuracy: 0.777\n",
      "Epoch 30000\tTrain Accuracy: 1.000\tTraining Loss: 0.060\tTest Accuracy: 0.771\n",
      "Epoch 35000\tTrain Accuracy: 1.000\tTraining Loss: 0.057\tTest Accuracy: 0.768\n",
      "Epoch 40000\tTrain Accuracy: 1.000\tTraining Loss: 0.054\tTest Accuracy: 0.765\n",
      "Epoch 45000\tTrain Accuracy: 1.000\tTraining Loss: 0.052\tTest Accuracy: 0.760\n",
      "Epoch 50000\tTrain Accuracy: 1.000\tTraining Loss: 0.049\tTest Accuracy: 0.756\n",
      "Epoch 55000\tTrain Accuracy: 1.000\tTraining Loss: 0.048\tTest Accuracy: 0.753\n",
      "Epoch 60000\tTrain Accuracy: 1.000\tTraining Loss: 0.046\tTest Accuracy: 0.750\n",
      "Epoch 65000\tTrain Accuracy: 1.000\tTraining Loss: 0.044\tTest Accuracy: 0.747\n",
      "Epoch 70000\tTrain Accuracy: 1.000\tTraining Loss: 0.043\tTest Accuracy: 0.744\n",
      "Epoch 75000\tTrain Accuracy: 1.000\tTraining Loss: 0.042\tTest Accuracy: 0.743\n",
      "Epoch 80000\tTrain Accuracy: 1.000\tTraining Loss: 0.041\tTest Accuracy: 0.739\n",
      "Epoch 85000\tTrain Accuracy: 1.000\tTraining Loss: 0.040\tTest Accuracy: 0.737\n",
      "Epoch 90000\tTrain Accuracy: 1.000\tTraining Loss: 0.039\tTest Accuracy: 0.735\n",
      "Epoch 95000\tTrain Accuracy: 1.000\tTraining Loss: 0.038\tTest Accuracy: 0.733\n"
     ]
    }
   ],
   "source": [
    "beta_gd = gd(X, Y, epochs=100000, epochs_per_print=5000, X_te = X_te_mod, Y_te = Y_te_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\tTrain Accuracy: 0.538\tTraining Loss: 1.064\tTest Accuracy: 0.552\n",
      "Epoch 100\tTrain Accuracy: 0.892\tTraining Loss: 0.380\tTest Accuracy: 0.839\n",
      "Epoch 200\tTrain Accuracy: 0.908\tTraining Loss: 0.332\tTest Accuracy: 0.842\n",
      "Epoch 300\tTrain Accuracy: 0.918\tTraining Loss: 0.305\tTest Accuracy: 0.841\n",
      "Epoch 400\tTrain Accuracy: 0.934\tTraining Loss: 0.285\tTest Accuracy: 0.840\n",
      "Epoch 500\tTrain Accuracy: 0.944\tTraining Loss: 0.270\tTest Accuracy: 0.839\n",
      "Epoch 600\tTrain Accuracy: 0.950\tTraining Loss: 0.257\tTest Accuracy: 0.839\n",
      "Epoch 700\tTrain Accuracy: 0.954\tTraining Loss: 0.246\tTest Accuracy: 0.839\n",
      "Epoch 800\tTrain Accuracy: 0.960\tTraining Loss: 0.237\tTest Accuracy: 0.839\n",
      "Epoch 900\tTrain Accuracy: 0.962\tTraining Loss: 0.229\tTest Accuracy: 0.838\n",
      "Epoch 1000\tTrain Accuracy: 0.962\tTraining Loss: 0.222\tTest Accuracy: 0.837\n",
      "Epoch 1100\tTrain Accuracy: 0.962\tTraining Loss: 0.216\tTest Accuracy: 0.836\n",
      "Epoch 1200\tTrain Accuracy: 0.968\tTraining Loss: 0.210\tTest Accuracy: 0.836\n",
      "Epoch 1300\tTrain Accuracy: 0.970\tTraining Loss: 0.205\tTest Accuracy: 0.836\n",
      "Epoch 1400\tTrain Accuracy: 0.972\tTraining Loss: 0.200\tTest Accuracy: 0.835\n",
      "Epoch 1500\tTrain Accuracy: 0.974\tTraining Loss: 0.195\tTest Accuracy: 0.834\n",
      "Epoch 1600\tTrain Accuracy: 0.976\tTraining Loss: 0.191\tTest Accuracy: 0.833\n",
      "Epoch 1700\tTrain Accuracy: 0.976\tTraining Loss: 0.187\tTest Accuracy: 0.832\n",
      "Epoch 1800\tTrain Accuracy: 0.978\tTraining Loss: 0.183\tTest Accuracy: 0.831\n",
      "Epoch 1900\tTrain Accuracy: 0.978\tTraining Loss: 0.180\tTest Accuracy: 0.829\n",
      "Epoch 2000\tTrain Accuracy: 0.978\tTraining Loss: 0.177\tTest Accuracy: 0.827\n",
      "Epoch 5000\tTrain Accuracy: 0.990\tTraining Loss: 0.125\tTest Accuracy: 0.815\n",
      "Epoch 10000\tTrain Accuracy: 0.994\tTraining Loss: 0.094\tTest Accuracy: 0.800\n",
      "Epoch 15000\tTrain Accuracy: 0.998\tTraining Loss: 0.080\tTest Accuracy: 0.788\n",
      "Epoch 20000\tTrain Accuracy: 0.998\tTraining Loss: 0.071\tTest Accuracy: 0.782\n",
      "Epoch 25000\tTrain Accuracy: 1.000\tTraining Loss: 0.065\tTest Accuracy: 0.779\n",
      "Epoch 30000\tTrain Accuracy: 1.000\tTraining Loss: 0.061\tTest Accuracy: 0.771\n",
      "Epoch 35000\tTrain Accuracy: 1.000\tTraining Loss: 0.057\tTest Accuracy: 0.766\n",
      "Epoch 40000\tTrain Accuracy: 1.000\tTraining Loss: 0.054\tTest Accuracy: 0.763\n",
      "Epoch 45000\tTrain Accuracy: 1.000\tTraining Loss: 0.052\tTest Accuracy: 0.761\n"
     ]
    }
   ],
   "source": [
    "beta_sgd = sgd(X, Y, epochs=50000, epochs_per_print=5000, X_te = X_te_mod, Y_te = Y_te_mod, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, s, _ = np.linalg.svd(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition Number of X: 7119.050088619612\n"
     ]
    }
   ],
   "source": [
    "print(f'Condition Number of X: {s.max() / s.min()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7119.050088619669"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svds = svdvals(X)\n",
    "svds.max() / svds.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
